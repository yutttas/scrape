# 要件定義書 - Webスクレイピングツール

## 1. プロジェクト概要

### 1.1 目的
指定したWebページから、CSSセレクターに該当するテキストを抽出し、一覧表示するシンプルなブラウザベースのスクレイピングツールを提供する。

### 1.2 対象ユーザー
- 求人情報などのデータを1ページから抽出したいユーザー
- CSSセレクターの基本を理解しているユーザー

### 1.3 基本方針
**シンプル第一**: 複雑な機能は排除し、1ページのスクレイピングに特化したシンプルなツール

## 2. 機能要件

### 2.1 基本スクレイピング機能

#### 2.1.1 URL入力
- **必須項目**: スクレイピング対象のURL（1ページのみ）
- **入力形式**: テキストフィールド
- **検証**: URLの入力が必須

#### 2.1.2 CSSセレクター指定
- **必須項目**: 抽出対象要素を指定するCSSセレクター
- **入力形式**: テキストフィールド
- **例**: `.title`, `h3 a`, `td div h2`
- **検証**: セレクターの入力が必須

### 2.2 CORS対策機能

#### 2.2.1 プロキシ使用設定
- **デフォルト**: 有効
- **プロキシサービス**: `https://corsproxy.io/`
- **切り替え**: チェックボックスで有効/無効を切り替え可能
- **目的**: ブラウザのCORS制限を回避

#### 2.2.2 エラーハンドリング
- **403エラー**: サイトがリクエストをブロックしていることを通知
- **フェッチエラー**: CORS関連エラーの場合、プロキシ使用を提案

### 2.3 プリセット機能

#### 2.3.1 事前定義セレクター
以下の求人サイト用のプリセットを提供：
- **ジョブメドレー**: `h3 a`
- **レバウェル**: `h3 span`
- **ナース専科**: `h3`
- **ハローワーク**: `td div h2`

#### 2.3.2 プリセット動作
- プリセット選択時にCSSセレクターフィールドに自動入力
- 選択中のプリセットはハイライト表示
- 再度クリックで選択解除

### 2.4 結果表示機能

#### 2.4.1 テーブル表示
- **形式**: 単一カラムのテーブル
- **内容**: 抽出されたテキストを1行ずつ表示
- **スクロール**: 最大高さ400px、それ以上はスクロール表示

#### 2.4.2 コピー機能
- **ボタン**: 結果ヘッダーに「コピー」ボタン配置
- **動作**: 全結果を改行区切りでクリップボードにコピー
- **フィードバック**: コピー成功時に2秒間「コピー完了！」と表示

#### 2.4.3 進捗表示
- **スクレイピング中**: 「スクレイピング中...」メッセージ表示
- **ローディング**: スピナーアニメーション表示

### 2.5 操作機能

#### 2.5.1 スクレイピング実行
- **ボタンラベル**: 「スクレイピング開始」
- **実行中**: ボタン無効化、進捗メッセージ表示
- **アイコン**: 検索アイコン表示

#### 2.5.2 クリア機能
- **ボタンラベル**: 「クリア」
- **動作**: 全入力フィールドと結果をリセット
- **アイコン**: ゴミ箱アイコン表示

## 3. 非機能要件

### 3.1 パフォーマンス
- **対象**: 1ページのみ
- **処理速度**: 即座にフィードバック

### 3.2 UI/UX
- **レスポンシブデザイン**: 最大幅800pxのコンテナ
- **シンプルなレイアウト**: 必要最小限の入力項目
- **アニメーション**: フェードイン、ホバーエフェクト
- **アクセシビリティ**:
  - aria-label属性
  - role属性（エラー表示など）
  - フォーカス状態の視覚化

### 3.3 エラー表示
- **表示位置**: フォーム下部
- **スタイル**: 赤背景、赤枠線、改行保持
- **内容**: 具体的なエラー原因と解決策の提示

### 3.4 ブラウザ互換性
- **必須API**:
  - Fetch API
  - DOMParser
  - Clipboard API
  - querySelector/querySelectorAll

## 4. 技術仕様

### 4.1 フロントエンド
- **フレームワーク**: React 19.2.0
- **ビルドツール**: Vite 6.2.0
- **言語**: TypeScript 5.8.2

### 4.2 スクレイピング実装
- **方式**: クライアントサイドスクレイピング（サーバー不要）
- **HTML解析**: DOMParser API使用
- **HTTP通信**: Fetch API使用
- **対象**: 1ページのみ

### 4.3 データフロー
1. ユーザーがURL、セレクターを入力
2. スクレイピング実行ボタンをクリック
3. 指定されたページに対して：
   - URLを構築（プロキシ使用時はプロキシURLでラップ）
   - FetchでHTML取得
   - DOMParserでパース
   - querySelectorAllでセレクターに一致する要素を取得
   - textContentを抽出して配列に追加
4. 結果を表示

### 4.4 状態管理
- **ライブラリ**: なし（React useState使用）
- **主要な状態**:
  - `url`: 入力URL
  - `selector`: CSSセレクター
  - `result`: スクレイピング結果（文字列配列）
  - `loading`: ローディング状態
  - `error`: エラーメッセージ
  - `useProxy`: プロキシ使用フラグ
  - `selectedPreset`: 選択中のプリセット
  - `copyText`: コピーボタンのテキスト

## 5. 制約事項

### 5.1 技術的制約
- **対象**: 1ページのみ（複数ページ非対応）
- **JavaScript必須サイト**: SPAなど動的レンダリングサイトは取得不可
- **認証必要サイト**: ログイン必要なページは取得不可
- **CORS制限**: プロキシ経由でも取得できないサイトが存在

### 5.2 法的・倫理的考慮
- **robots.txt**: 遵守が望ましい（ツール側でチェックなし）
- **利用規約**: 各サイトの利用規約を確認する責任はユーザー側
- **負荷**: 1ページのみの取得のため、サーバー負荷は最小限

## 6. 削除された機能（以前のバージョンから）

以下の機能はシンプル化のため削除されました：
- 複数ページスクレイピング（URLパターン方式）
- ページネーション機能（次へリンク自動検出）
- 次へリンクセレクター
- ページ数指定

## 7. 将来的な拡張案（現時点では未実装）

### 7.1 データエクスポート
- CSV形式でのダウンロード
- JSON形式でのダウンロード

### 7.2 高度なスクレイピング
- 複数セレクターの同時指定
- 属性値の取得（href、srcなど）
- 正規表現フィルター

### 7.3 データ処理
- 重複除去
- ソート機能
- フィルタリング

## 8. 環境変数

### 8.1 GEMINI_API_KEY
- **設定場所**: `.env.local`
- **用途**: 現時点でコード内で未使用（将来的な拡張用）
- **注入方法**: Viteの`define`オプションで`process.env.GEMINI_API_KEY`として利用可能
